# TileLang 国产GPU开发项目文档（项目背景+快速上手+生态贡献）
## 一、项目背景
### 1. 行业痛点：国产GPU生态的核心挑战
当前智算与通用计算领域中，GPU内核开发面临双重困境：一方面，国际主流GPU开发语言学习成本高、代码量大，开发者需兼顾性能优化与生产力，门槛较高；另一方面，国产GPU虽在硬件性能上逐步追赶，但软件生态适配相对来说还有很大的进步空间，缺乏轻量化、高效的开发工具链，导致硬件算力难以充分释放，生态协同性不足。

### 2. 解决方案：TileLang的技术突破
TileLang作为TileLang社区主导的GPU内核领域专用语言，以“高效开发+性能不妥协”为核心，针对性解决行业痛点：
- **开发效率革命**：采用Python式简洁语法，实现FlashAttention算子仅需80行代码，并保持了与官方版本持平的性能。这种代码量的大幅减少不仅降低了开发门槛，也提高了维护性和可读性。；
- **分层接口适配**：提供3个层次编程接口，覆盖从初学者到专家的全阶段需求，降低国产GPU开发门槛；
- **多硬件兼容**：已在MACA曦云C500、英伟达H100/A100、AMD MI250/MI300X等多类GPU上验证适配，支持“cuda/hip/cpu”多目标编译，兼容性广泛。

### 3. 生态协同：MACA与开源社区的落地支持
为推动TileLang在国产GPU上的实际应用，MACA（国产高性能GPU代表厂商）与开源社区联合行动：
- **硬件适配**：MACA AI编译器团队和TileLang社区合作已提前参与该项目，探讨MACAGPU与TileLang的适配（开源仓库：[mcTileLang](https://gitee.com/metax-maca/mcTileLang)），通过MXMACA软件栈实现深度协同，核心算子性能接近国际主流产品。
- **在线环境搭建**：在模力方舟平台提供预配置的TileLang在线体验环境，开发者无需自行搭建硬件，直接基于曦云C500（64GB显存、Intel Xeon Gold 6530）来进行开发；
- **资源支持**：提供专属算力券降低体验成本，同时开源完整适配代码与文档，助力生态共建。

### 4. 项目意义
本项目通过“语言工具+国产硬件+在线平台”的组合，打破国产GPU生态“硬件强、软件弱”的僵局，为开发者提供“开箱即用”的国产GPU开发方案，推动中国算力产业从“单点突破”转向“生态共荣”，助力智算、通用计算领域的国产化替代与创新发展。

## 二、快速上手：TileLang 国产 GPU 开发实践
### 1. 环境准备：获取TileLang在线开发资源
#### 步骤1：进入模力方舟算力市场
访问[模力方舟](https://ai.gitee.com/compute), 点击顶部导航栏“算力市场”，进入MACAGPU资源租用页面。

#### 步骤2：领取TileLang专属算力券
- 参与比赛活动，领取TileLang专属算力券；
- 算力券可直接兑换曦云C系列GPU容器资源，用于TileLang开发体验。

#### 步骤3：选择TileLang镜像与配置
- **硬件配置选择**：默认选择“曦云C500”GPU，单卡配置为64GB显存、12核Intel Xeon Gold 6530 CPU
- **镜像选择**：在“镜像”列表中勾选“基础镜像”下的“TileLang 0.1.5 
- **计费方式**：支持按量收费、包日/包周/包月。

### 2. 容器启动与TileLang验证
#### 步骤1：启动GPU容器
完成配置与算力券兑换后，点击“启动容器”，等待容器初始化（通常耗时1-3分钟，可在“工作台”查看进度）。

#### 步骤2：执行快速验证命令
容器启动后，通过终端输入以下命令，验证TileLang环境可用性：
```bash
# 进入TileLang示例目录
cd /root/mcTileLang/
# 运行快速启动示例
python3 ./examples/quickstart.py
```

#### 步骤3：确认验证结果
若终端输出以下信息，说明环境正常：
- 张量输出（如`tensor([[ -1.4619, -19.9844, ... ]], device='cuda:0', dtype=torch.float16)`）；
- 匹配提示（`Kernel output matches PyTorch reference`）；
- 延迟数据（如`Latency:0.11110399663448334 ms`）。

可额外执行`mx-smi`命令，查看曦云C500 GPU状态（如温度、显存占用、功率等），确认硬件资源正常调用。

### 3. 进阶体验：TileLang算子开发
#### 步骤1：参考官方文档
访问MACA开源项目文档，获取算子开发教程与API说明。

#### 步骤2：尝试核心算子开发
基于示例代码修改，开发自定义GPU算子（如简化版GEMM算子））。

#### 步骤3：参与生态贡献
若开发的算子具备通用性，可通过[gitee](https://gitee.com/metax-maca/mcTileLang)提交PR参与TileLang国产GPU生态共建。


## 三、生态贡献指南：邀您共建TileLang国产GPU生态
为持续完善mcTileLang仓库功能、降低开发门槛，诚邀所有开发者参与贡献，重点欢迎**Issue反馈**与**Docs/Example类型PR**，评分详见[Task](Task.md)具体指南如下：

### 1. 积极反馈：提交Issue助力仓库优化
当您遇到以下场景时，欢迎通过仓库“Issues”模块提交反馈，帮助团队定位问题、明确方向：
- **功能需求**：需要新增算子示例（如卷积、稀疏注意力）、补充特定硬件适配文档；
- **Bug反馈**：运行示例代码报错、性能不符合预期、编译过程异常（需附报错日志与环境信息）；
- **文档疑问**：现有文档（如安装步骤、API说明）不清晰、存在疏漏；
- **优化建议**：对内核性能、接口易用性、编译速度的改进想法。

> 提交Issue时，请选择对应标签（如“feat request”“bug”“doc”），描述清晰场景与需求，便于社区快速响应。

### 2. 主动共建：提交Docs/Example类型PR
mcTileLang仓库的`docs`（文档）与`examples`（示例）目录是生态核心组成部分，尤其欢迎以下类型PR，共建更易用的开发资源：

#### （1）Docs类型PR：完善文档体系
- **教程迁移**：将已有的基于cuda的教程文档迁移到metax上
- **新增教程**：补充“TileLang布局优化实战”“MACAGPU性能调优指南”等进阶教程；
- **更新说明**：同步API变更（如新增的接口）、修正安装步骤中的过时信息；
- **补充案例**：在文档中添加“常见问题排查”（如容器启动失败、编译报错解决）。

#### （2）Example类型PR：丰富算子示例
- **新增算子**：提交RetNet、Mamba等新兴模型的TileLang实现，或补充现有算子的优化版本（如支持不同精度或者混合精度的算子）；
- **硬件适配**：提供算子在GPU（如曦云C500）上的适配示例与性能分析。

#### （3）PR提交流程
1. Fork mcTileLang仓库到个人账号；
2. 创建专属分支（如`doc/update-install-guide`、`example/add-fp8-gemm`）；
3. 完成修改后，提交PR并关联相关Issue（如没有可以自己提交Issue并进行关联）；
4. 参考仓库`CONTRIBUTING.md`确保代码风格、文档格式符合规范，等待审核合并。


## 四、资源汇总
- 仓库地址：https://gitee.com/metax-maca/mcTileLang
- 在线体验：https://ai.gitee.com/compute
- 文档参考：《曦云系列_通用计算GPU_快速上手指南》
- 社区交流：加入社区参与讨论（仓库README有入口）
